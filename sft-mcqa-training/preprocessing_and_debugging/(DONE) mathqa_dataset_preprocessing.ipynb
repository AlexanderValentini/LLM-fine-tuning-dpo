{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code origin\n",
    "#Author: Alexander Valentini\n",
    "#Here we don't apply the chat template, but just do preliminary data processing\n",
    "\n",
    "import datasets\n",
    "import re\n",
    "import jsonlines\n",
    "from typing import Literal, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOICES_PATTERN = re.compile(r\"a \\) (.+) , b \\) (.+) , c \\) (.+) , d \\) (.+) , e \\) (.+)\")\n",
    "CHOICES_PATTERN_2 = re.compile(r\"\\['a \\) ([^']+)', 'b \\) ([^']+)', 'c \\) ([^']+)', 'd \\) ([^']+)', 'e \\) ([^']+)'\\]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\AppData\\Roaming\\Python\\Python310\\site-packages\\datasets\\load.py:1491: FutureWarning: The repository for allenai/math_qa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/allenai/math_qa\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6931dcf049f2414c9698f73428865880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b46dc8e7f843dc8abb08bd2284c5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e5447e1f0f4a0ab6c027a7da5ab4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e736f47c3b4f459c7c419e6cd32958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/29837 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e12b64fd9c4bdfa9a243bd6b707811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e82f95d99048da8deb29916c0629cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
       "        num_rows: 29837\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
       "        num_rows: 2985\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
       "        num_rows: 4475\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How the dataset looks when pulled from huggingface:\n",
    "dataset = datasets.load_dataset(\"allenai/math_qa\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultDict(TypedDict):\n",
    "    subject: str\n",
    "    question: str\n",
    "    answer: Literal[\"A\", \"B\", \"C\", \"D\", \"E\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Its because we need to write it in the format below, instead of the one from huggingface. \n",
    "#Which uses \"a ) option\" style\n",
    "def craft_mcqa_question(question: str, options: tuple[str, str, str, str, str], /) -> str:\n",
    "    assert all(option.strip() == option for option in options)\n",
    "    joined_options = f\"A. {options[0]}\\nB. {options[1]}\\nC. {options[2]}\\nD. {options[3]}\\nE. {options[4]}\"\n",
    "    return f\"Question: {question}\\n\\nOptions:\\n{joined_options}\\n\\nAnswer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We convert all lower case options in the dataset to upper case:\n",
    "def upper_case(letter: Literal[\"a\", \"b\", \"c\", \"d\", \"e\"], /) -> Literal[\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "    if letter == \"a\":\n",
    "        return \"A\"\n",
    "    if letter == \"b\":\n",
    "        return \"B\"\n",
    "    if letter == \"c\":\n",
    "        return \"C\"\n",
    "    if letter == \"d\":\n",
    "        return \"D\"\n",
    "    if letter == \"e\":\n",
    "        return \"E\"\n",
    "    raise ValueError(\"Incorrect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(data: datasets.arrow_dataset.Dataset, /) -> list[ResultDict]:\n",
    "    results: list[ResultDict] = []\n",
    "    for line in data:\n",
    "        assert isinstance(line, dict)\n",
    "\n",
    "        # It should have keys in the dictionary with these names\n",
    "        problem: str = line[\"Problem\"]\n",
    "        options: str = line[\"options\"]\n",
    "        correct: str = line[\"correct\"]\n",
    "        category: str = line[\"category\"]\n",
    "\n",
    "        # Verify types (the dataset should contain strings)\n",
    "        assert isinstance(problem, str)\n",
    "        assert isinstance(options, str)\n",
    "        assert isinstance(correct, str)\n",
    "        assert isinstance(category, str)\n",
    "        assert correct in (\"a\", \"b\", \"c\", \"d\", \"e\")\n",
    "\n",
    "        # Parse options\n",
    "        #We want to assert it has the expected format from huggingface before we change it. To make sure \n",
    "        #it is at least downloaded and loaded correctly from huggingface before further preprocessing:\n",
    "        options_match = CHOICES_PATTERN.fullmatch(options)\n",
    "        if options_match is None:\n",
    "            options_match = CHOICES_PATTERN_2.fullmatch(options)\n",
    "            assert options_match is not None\n",
    "\n",
    "        #There needs to be 5 keys we are extracting:\n",
    "        # Extracting groups\n",
    "        groups: tuple[str, ...] = options_match.groups()\n",
    "        assert len(groups) == 5\n",
    "        assert all(isinstance(x, str) for x in groups)\n",
    "\n",
    "        #We end up with 3 keys in the dictionary for each datapoint (Some info is removed). We removed the rationale\n",
    "        #to make the training process simpler:\n",
    "        results.append({\n",
    "            \"question\": craft_mcqa_question(problem, groups),\n",
    "            \"answer\": upper_case(correct),\n",
    "            \"subject\": category\n",
    "        })\n",
    "\n",
    "    # Return results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = parse_dataset(dataset[\"train\"])\n",
    "test_data = parse_dataset(dataset[\"test\"])\n",
    "validation_data = parse_dataset(dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Question: the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\\n\\nOptions:\\nA. rs . 400\\nB. rs . 300\\nC. rs . 500\\nD. rs . 350\\nE. none of these\\n\\nAnswer:\",\n",
       " 'answer': 'A',\n",
       " 'subject': 'gain'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New Format:\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(\"datasets/mcqa/mcqa_math_train_dataset.jsonl\", \"w\") as f:\n",
    "    f.write_all(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(\"datasets/mcqa/mcqa_math_test_dataset.jsonl\", \"w\") as f:\n",
    "    f.write_all(test_data)\n",
    "with jsonlines.open(\"datasets/mcqa/mcqa_math_validation_dataset.jsonl\", \"w\") as f:\n",
    "    f.write_all(validation_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
